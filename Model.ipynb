{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e22e8e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "# import ffmpeg\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "# from pydub import AudioSegment as AS\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import keras\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, Conv1D, MaxPooling1D, AveragePooling1D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Bidirectional, LSTM, Reshape\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a36a97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acfe4ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_malloc_async\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "print(os.getenv('TF_GPU_ALLOCATOR'))\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('error')\n",
    "    \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01c13bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf4ddbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = joblib.load('librosa_all_samples_ohe.joblib')\n",
    "# decoded_labels= le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "119e3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_train_df = pd.read_pickle('librosa_all_samples_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "514bfb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack([np.array(val) for val in all_samples_train_df['features'].values], axis=0)\n",
    "X_train.shape\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "\n",
    "y_train = np.stack([np.array(val) for val in all_samples_train_df['label'].values], axis=0)\n",
    "# X_train = np.swapaxes(X_train,1,2)\n",
    "del all_samples_train_df\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b62934cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9573, 128, 308, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a8f0552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f531aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_valid_df = pd.read_pickle('librosa_all_samples_valid.pkl')\n",
    "X_valid = np.stack([np.array(val) for val in all_samples_valid_df['features'].values], axis=0)\n",
    "y_valid = np.stack([np.array(val) for val in all_samples_valid_df['label'].values], axis=0)\n",
    "X_valid = (X_valid - mean)/std\n",
    "# X_valid = np.swapaxes(X_valid,1,2)\n",
    "del all_samples_valid_df\n",
    "\n",
    "valid_gen = DataGenerator(X_valid, y_valid, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ca13fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlrop = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=4, min_lr=0.000001)\n",
    "checkpoint_path = 'E:/Dissertation/best_weights.hdf5'\n",
    "# mcp_save = ModelCheckpoint(checkpoint_path, save_best_only=True,\n",
    "#                            monitor='val_accuracy',\n",
    "#                            mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ffd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(nr_labels):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(308, 128)))\n",
    "    model.add(Conv1D(256, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(Conv1D(256, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(128, return_sequences=True, dropout=0.1))\n",
    "    model.add(LSTM(128, return_sequences=False, dropout=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(nr_labels, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d5492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(nr_labels):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences = True, input_shape=(308, 128)))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(nr_labels, activation = 'softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1a005a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model3(nr_labels):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(32, kernel_size=5, padding='same',strides = 1, activation='relu', input_shape=(30, 308)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling1D())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv1D(32, kernel_size=5, padding='same',strides = 1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling1D())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv1D(32, kernel_size=5, padding='same',strides = 1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling1D())\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv1D(32, kernel_size=5, padding='same',strides = 1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling1D())\n",
    "    model.add(Dropout(0.1)) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())   \n",
    "    \n",
    "    \n",
    "    model.add(Dense(nr_labels, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34e0f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model4(nr_labels):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu', input_shape = (30, 308, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=5, padding=\"same\", activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Dense(nr_labels, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06ba9b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 30, 308, 64)       1664      \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 30, 308, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling2d_12 (Avera  (None, 15, 154, 64)      0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 15, 154, 64)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 15, 154, 64)       102464    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 15, 154, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling2d_13 (Avera  (None, 7, 77, 64)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 7, 77, 64)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 7, 77, 64)         102464    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 7, 77, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling2d_14 (Avera  (None, 3, 38, 64)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 3, 38, 64)         0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 3, 38, 64)         102464    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 3, 38, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " average_pooling2d_15 (Avera  (None, 1, 19, 64)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 19, 64)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1216)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               155776    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 467,271\n",
      "Trainable params: 466,503\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model4(y_train.shape[1])\n",
    "model.build()\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "                optimizer='adam', \n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ade95bcd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "225/225 [==============================] - 42s 168ms/step - loss: 1.4055 - accuracy: 0.4815 - val_loss: 1.6818 - val_accuracy: 0.3517 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 1.0770 - accuracy: 0.5950 - val_loss: 1.3255 - val_accuracy: 0.4996 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.9610 - accuracy: 0.6348 - val_loss: 1.0336 - val_accuracy: 0.6282 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "225/225 [==============================] - 37s 163ms/step - loss: 0.8781 - accuracy: 0.6673 - val_loss: 0.8838 - val_accuracy: 0.6600 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.8165 - accuracy: 0.6893 - val_loss: 0.9461 - val_accuracy: 0.6475 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.7491 - accuracy: 0.7163 - val_loss: 0.8512 - val_accuracy: 0.6817 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.6937 - accuracy: 0.7377 - val_loss: 0.9484 - val_accuracy: 0.6408 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.6439 - accuracy: 0.7604 - val_loss: 0.8973 - val_accuracy: 0.6717 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.6038 - accuracy: 0.7725 - val_loss: 0.8521 - val_accuracy: 0.7076 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.5601 - accuracy: 0.7924 - val_loss: 0.9116 - val_accuracy: 0.6976 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.5291 - accuracy: 0.8029 - val_loss: 0.8526 - val_accuracy: 0.7151 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.4994 - accuracy: 0.8148 - val_loss: 0.8829 - val_accuracy: 0.6901 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "225/225 [==============================] - 37s 163ms/step - loss: 0.4748 - accuracy: 0.8251 - val_loss: 0.9084 - val_accuracy: 0.7218 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "225/225 [==============================] - 37s 163ms/step - loss: 0.4490 - accuracy: 0.8325 - val_loss: 0.9461 - val_accuracy: 0.6942 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "225/225 [==============================] - 37s 162ms/step - loss: 0.4296 - accuracy: 0.8409 - val_loss: 0.9600 - val_accuracy: 0.6976 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "225/225 [==============================] - 37s 163ms/step - loss: 0.4073 - accuracy: 0.8490 - val_loss: 0.9199 - val_accuracy: 0.7051 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.3909 - accuracy: 0.8544 - val_loss: 0.9468 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.3782 - accuracy: 0.8592 - val_loss: 0.9300 - val_accuracy: 0.7076 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.3675 - accuracy: 0.8656 - val_loss: 1.0463 - val_accuracy: 0.6992 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.3490 - accuracy: 0.8715 - val_loss: 1.0586 - val_accuracy: 0.7109 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.3393 - accuracy: 0.8740 - val_loss: 1.0777 - val_accuracy: 0.7251 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.3291 - accuracy: 0.8777 - val_loss: 1.0602 - val_accuracy: 0.7068 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.3251 - accuracy: 0.8788 - val_loss: 1.0947 - val_accuracy: 0.6926 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "225/225 [==============================] - 35s 156ms/step - loss: 0.3080 - accuracy: 0.8864 - val_loss: 1.1064 - val_accuracy: 0.7218 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "225/225 [==============================] - 35s 156ms/step - loss: 0.3056 - accuracy: 0.8877 - val_loss: 1.1158 - val_accuracy: 0.7218 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "225/225 [==============================] - 35s 155ms/step - loss: 0.2979 - accuracy: 0.8904 - val_loss: 1.0057 - val_accuracy: 0.7277 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "225/225 [==============================] - 35s 156ms/step - loss: 0.2873 - accuracy: 0.8941 - val_loss: 1.0297 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "225/225 [==============================] - 35s 156ms/step - loss: 0.2877 - accuracy: 0.8948 - val_loss: 1.1466 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "225/225 [==============================] - 35s 155ms/step - loss: 0.2785 - accuracy: 0.8969 - val_loss: 0.9732 - val_accuracy: 0.7385 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.2712 - accuracy: 0.9006 - val_loss: 1.0682 - val_accuracy: 0.7277 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.2651 - accuracy: 0.9027 - val_loss: 1.0123 - val_accuracy: 0.7210 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 0.2600 - accuracy: 0.9057 - val_loss: 0.9669 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "225/225 [==============================] - 36s 161ms/step - loss: 0.2553 - accuracy: 0.9068 - val_loss: 1.0254 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "225/225 [==============================] - 35s 158ms/step - loss: 0.2535 - accuracy: 0.9075 - val_loss: 1.1637 - val_accuracy: 0.7051 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "225/225 [==============================] - 35s 155ms/step - loss: 0.2487 - accuracy: 0.9093 - val_loss: 1.0808 - val_accuracy: 0.7143 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.2467 - accuracy: 0.9097 - val_loss: 1.1450 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.2425 - accuracy: 0.9102 - val_loss: 1.1395 - val_accuracy: 0.7243 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.2361 - accuracy: 0.9134 - val_loss: 1.0503 - val_accuracy: 0.7268 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.2312 - accuracy: 0.9153 - val_loss: 1.2223 - val_accuracy: 0.7218 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.2305 - accuracy: 0.9153 - val_loss: 1.1509 - val_accuracy: 0.7310 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.2214 - accuracy: 0.9189 - val_loss: 1.2320 - val_accuracy: 0.7235 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.2255 - accuracy: 0.9182 - val_loss: 1.2639 - val_accuracy: 0.7151 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "225/225 [==============================] - 36s 161ms/step - loss: 0.2198 - accuracy: 0.9189 - val_loss: 1.1059 - val_accuracy: 0.7327 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "225/225 [==============================] - 36s 162ms/step - loss: 0.2208 - accuracy: 0.9185 - val_loss: 1.4433 - val_accuracy: 0.6967 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "225/225 [==============================] - 35s 156ms/step - loss: 0.2115 - accuracy: 0.9244 - val_loss: 1.0401 - val_accuracy: 0.7377 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.2136 - accuracy: 0.9217 - val_loss: 1.2608 - val_accuracy: 0.7093 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.2065 - accuracy: 0.9240 - val_loss: 1.2451 - val_accuracy: 0.7310 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.2086 - accuracy: 0.9239 - val_loss: 1.3073 - val_accuracy: 0.7109 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.2003 - accuracy: 0.9262 - val_loss: 1.0466 - val_accuracy: 0.7444 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.2003 - accuracy: 0.9268 - val_loss: 1.2015 - val_accuracy: 0.7277 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.2030 - accuracy: 0.9256 - val_loss: 1.2802 - val_accuracy: 0.7118 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1955 - accuracy: 0.9284 - val_loss: 1.2229 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1985 - accuracy: 0.9271 - val_loss: 1.1832 - val_accuracy: 0.7318 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1937 - accuracy: 0.9293 - val_loss: 1.4580 - val_accuracy: 0.6992 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "225/225 [==============================] - 34s 149ms/step - loss: 0.1911 - accuracy: 0.9313 - val_loss: 1.2812 - val_accuracy: 0.7160 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "225/225 [==============================] - 34s 149ms/step - loss: 0.1889 - accuracy: 0.9304 - val_loss: 1.1870 - val_accuracy: 0.7402 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "225/225 [==============================] - 34s 149ms/step - loss: 0.1905 - accuracy: 0.9310 - val_loss: 1.1730 - val_accuracy: 0.7302 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "225/225 [==============================] - 34s 149ms/step - loss: 0.1898 - accuracy: 0.9311 - val_loss: 1.2284 - val_accuracy: 0.7251 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "225/225 [==============================] - 34s 149ms/step - loss: 0.1829 - accuracy: 0.9344 - val_loss: 1.3660 - val_accuracy: 0.7101 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "225/225 [==============================] - 34s 149ms/step - loss: 0.1802 - accuracy: 0.9336 - val_loss: 1.2808 - val_accuracy: 0.7210 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "225/225 [==============================] - 34s 149ms/step - loss: 0.1848 - accuracy: 0.9332 - val_loss: 1.3636 - val_accuracy: 0.7101 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "225/225 [==============================] - 34s 149ms/step - loss: 0.1772 - accuracy: 0.9361 - val_loss: 1.3624 - val_accuracy: 0.7168 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "225/225 [==============================] - 34s 149ms/step - loss: 0.1784 - accuracy: 0.9346 - val_loss: 1.4892 - val_accuracy: 0.6834 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "225/225 [==============================] - 34s 153ms/step - loss: 0.1759 - accuracy: 0.9349 - val_loss: 1.3470 - val_accuracy: 0.7160 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "225/225 [==============================] - 35s 154ms/step - loss: 0.1761 - accuracy: 0.9356 - val_loss: 1.3541 - val_accuracy: 0.7101 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "225/225 [==============================] - 34s 153ms/step - loss: 0.1748 - accuracy: 0.9366 - val_loss: 1.3870 - val_accuracy: 0.7118 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "225/225 [==============================] - 34s 153ms/step - loss: 0.1689 - accuracy: 0.9373 - val_loss: 1.2986 - val_accuracy: 0.7201 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1688 - accuracy: 0.9389 - val_loss: 1.3220 - val_accuracy: 0.7059 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1734 - accuracy: 0.9360 - val_loss: 1.3964 - val_accuracy: 0.7251 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1693 - accuracy: 0.9394 - val_loss: 1.3746 - val_accuracy: 0.7076 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "225/225 [==============================] - 34s 153ms/step - loss: 0.1629 - accuracy: 0.9419 - val_loss: 1.1615 - val_accuracy: 0.7435 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1664 - accuracy: 0.9401 - val_loss: 1.3317 - val_accuracy: 0.7176 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "225/225 [==============================] - 35s 153ms/step - loss: 0.1636 - accuracy: 0.9411 - val_loss: 1.3927 - val_accuracy: 0.7118 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1607 - accuracy: 0.9427 - val_loss: 1.3159 - val_accuracy: 0.7101 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1615 - accuracy: 0.9412 - val_loss: 1.2403 - val_accuracy: 0.7251 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1585 - accuracy: 0.9427 - val_loss: 1.3408 - val_accuracy: 0.7160 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1567 - accuracy: 0.9424 - val_loss: 1.2420 - val_accuracy: 0.7302 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1559 - accuracy: 0.9433 - val_loss: 1.3776 - val_accuracy: 0.7160 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1537 - accuracy: 0.9435 - val_loss: 1.2127 - val_accuracy: 0.7352 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1531 - accuracy: 0.9448 - val_loss: 1.2698 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "225/225 [==============================] - 34s 151ms/step - loss: 0.1583 - accuracy: 0.9430 - val_loss: 1.4561 - val_accuracy: 0.6959 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1527 - accuracy: 0.9453 - val_loss: 1.4248 - val_accuracy: 0.6850 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "225/225 [==============================] - 34s 151ms/step - loss: 0.1520 - accuracy: 0.9451 - val_loss: 1.4719 - val_accuracy: 0.7034 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "225/225 [==============================] - 34s 151ms/step - loss: 0.1521 - accuracy: 0.9453 - val_loss: 1.3716 - val_accuracy: 0.7168 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1524 - accuracy: 0.9456 - val_loss: 1.5018 - val_accuracy: 0.7168 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "225/225 [==============================] - 34s 151ms/step - loss: 0.1531 - accuracy: 0.9455 - val_loss: 1.4905 - val_accuracy: 0.7126 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "225/225 [==============================] - 34s 151ms/step - loss: 0.1512 - accuracy: 0.9453 - val_loss: 1.5200 - val_accuracy: 0.7026 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "225/225 [==============================] - 34s 151ms/step - loss: 0.1479 - accuracy: 0.9463 - val_loss: 1.4920 - val_accuracy: 0.7168 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1485 - accuracy: 0.9466 - val_loss: 1.5651 - val_accuracy: 0.7034 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "225/225 [==============================] - 34s 151ms/step - loss: 0.1437 - accuracy: 0.9483 - val_loss: 1.2762 - val_accuracy: 0.7310 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1453 - accuracy: 0.9477 - val_loss: 1.3428 - val_accuracy: 0.7293 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1439 - accuracy: 0.9476 - val_loss: 1.3316 - val_accuracy: 0.7327 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1439 - accuracy: 0.9493 - val_loss: 1.2976 - val_accuracy: 0.7185 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1423 - accuracy: 0.9508 - val_loss: 1.3025 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1385 - accuracy: 0.9506 - val_loss: 1.5642 - val_accuracy: 0.7001 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "225/225 [==============================] - 34s 150ms/step - loss: 0.1417 - accuracy: 0.9490 - val_loss: 1.4056 - val_accuracy: 0.7251 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.1381 - accuracy: 0.9500 - val_loss: 1.2820 - val_accuracy: 0.7318 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "225/225 [==============================] - 35s 155ms/step - loss: 0.1389 - accuracy: 0.9494 - val_loss: 1.5415 - val_accuracy: 0.7101 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "225/225 [==============================] - 35s 154ms/step - loss: 0.1401 - accuracy: 0.9495 - val_loss: 1.5191 - val_accuracy: 0.7126 - lr: 0.0010\n",
      "Epoch 100/200\n",
      " 76/225 [=========>....................] - ETA: 22s - loss: 0.1279 - accuracy: 0.9541"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6128\\273208655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrlrop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training done...moving to next set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dissertation\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dissertation\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[0;32m   1210\u001b[0m                 \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dissertation\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1248\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m       \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[0;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dissertation\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32me:\\dissertation\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dissertation\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=200, batch_size = BATCH_SIZE, callbacks=[rlrop]\n",
    ")\n",
    "print('Training done...moving to next set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history):\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Sparse Categorical Crossentropy')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    \n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['categorical_accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_categorical_accuracy'], color='orange', label='test')\n",
    "\n",
    "    # save plot to file\n",
    "    filename = os.getcwd()\n",
    "    plt.savefig(filename + '/model_performance_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5021b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e33bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_samples_test_df = pd.read_pickle('all_samples_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea872f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

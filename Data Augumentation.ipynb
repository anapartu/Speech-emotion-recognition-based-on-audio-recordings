{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec48134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\dissertation\\venv\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "# import ffmpeg\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pydub import AudioSegment as AS\n",
    "from pydub import effects\n",
    "import noisereduce as nr\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import keras\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
    "from keras.layers import Bidirectional, LSTM, Reshape\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import datetime\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e7e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 157409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9cc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal(df):\n",
    "#     librosa_signals = []\n",
    "#     normalized_librosa_signals = []\n",
    "    trimmed_librosa_signals = []\n",
    "#     pydub_signals = []\n",
    "#     normalized_pydub_signals = []\n",
    "#     trimmed_pydub_signals = []\n",
    "    librosa_lens = []\n",
    "#     pydub_lens = []\n",
    "    for index, row in df.iterrows():\n",
    "        path  = row['path']\n",
    "#         print(path)\n",
    "        librosa_signal, sr = librosa.load(path)\n",
    "#         librosa_signals.append(librosa_signal)\n",
    "        normalized_librosa_signal = librosa.util.normalize(librosa_signal)\n",
    "#         normalized_librosa_signals.append(normalized_librosa_signal)\n",
    "        trimmed_librosa_signal, index = librosa.effects.trim(normalized_librosa_signal, top_db = 30)\n",
    "        trimmed_librosa_signals.append(trimmed_librosa_signal)\n",
    "        librosa_len = len(trimmed_librosa_signal)\n",
    "        librosa_lens.append(librosa_len)\n",
    "#         segment = AS.from_file(path)\n",
    "#         segment = segment.set_channels(1)\n",
    "#         segment = segment.set_frame_rate(22050)\n",
    "#         pydub_signal = np.array(segment.get_array_of_samples(), dtype = 'float32')\n",
    "#         pydub_signals.append(pydub_signal)\n",
    "#         normalized_segment = effects.normalize(segment, headroom = 5.0)\n",
    "#         normalized_pydub_signal = np.array(normalized_segment.get_array_of_samples(), dtype = 'float32')\n",
    "#         normalized_pydub_signals.append(normalized_pydub_signal)\n",
    "#         trimmed_pydub_signal, index2 = librosa.effects.trim(normalized_pydub_signal, top_db = 30)\n",
    "#         trimmed_pydub_signals.append(trimmed_pydub_signal)\n",
    "#         pydub_len = len(trimmed_pydub_signal)\n",
    "#         pydub_lens.append(pydub_len)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "#     df['librosa_signals'] = librosa_signals\n",
    "#     df['normalized_librosa_signals'] = normalized_librosa_signals\n",
    "    df['trimmed_librosa_signals'] = trimmed_librosa_signals\n",
    "    df['librosa_lens'] = librosa_lens\n",
    "#     df['pydub_signals'] = pydub_signals\n",
    "#     df['normalized_pydub_signals'] = normalized_pydub_signals\n",
    "#     df['trimmed_pydub_signals'] = trimmed_pydub_signals\n",
    "#     df['pydub_lens'] = pydub_lens\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195a70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_validation_test(df, train_size=0.8):\n",
    "    train_df, remainder_df = train_test_split(df, test_size=1-train_size)\n",
    "    validation_df, test_df = train_test_split(remainder_df, test_size=0.5)\n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c67ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data):\n",
    "    mel_spectogram = librosa.feature.melspectrogram(y=data, sr = 22050)\n",
    "    features = librosa.power_to_db(mel_spectogram)\n",
    "#     features = np.expand_dims(logspec, axis=-1)\n",
    "#     mfcc = librosa.feature.mfcc(y = data, sr=22050, n_mfcc=20)\n",
    "#     features = np.expand_dims(mfcc, axis=-1)\n",
    "#     features = librosa.feature.mfcc(y = data, sr=22050, n_mfcc=20)\n",
    "    #deltas\n",
    "#     d1 = librosa.feature.delta(mfcc, order=1)\n",
    "#     d2 = librosa.feature.delta(mfcc, order=2)\n",
    "#     features = np.concatenate((mfcc, d1, d2), axis=0)\n",
    "    #rms and zcr\n",
    "#     rms = librosa.feature.rms(y = data)\n",
    "#     zcr = librosa.feature.zero_crossing_rate(y = data)\n",
    "#     features = np.concatenate((mfcc, rms, zcr), axis=0)\n",
    "    return features\n",
    "\n",
    "def add_noise(data):\n",
    "    noise_amp = 0.005*np.random.uniform()*np.amax(data)\n",
    "    data = data.astype('float32') + noise_amp * np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_time_stretching_slower(data, rate=0.5):\n",
    "    data = librosa.effects.time_stretch(data, rate=rate)\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_time_stretching_faster(data, rate=2.0):\n",
    "    data = librosa.effects.time_stretch(data, rate=rate)\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_time_shifting(data):\n",
    "    data = np.roll(data, int(22050/10))\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_pitch_shifting(data):\n",
    "    data = librosa.effects.pitch_shift(y=data, sr=22050, n_steps = -5)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_freq_mask(df):\n",
    "    df['freq_mask'] = df['features'].apply(lambda x: np.array(tfio.audio.freq_mask(x, param=4), dtype=np.float32))\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_time_mask(df):\n",
    "    df['time_mask'] = df['features'].apply(lambda x: np.array(tfio.audio.time_mask(x, param=4), dtype=np.float32))\n",
    "    return df\n",
    "\n",
    "def augument_mfcc(df):\n",
    "    df = add_freq_mask(df.copy())\n",
    "    df = add_time_mask(df.copy())\n",
    "    return df\n",
    "\n",
    "def melt_mfcc_df(df):\n",
    "    df = df.melt(\n",
    "        id_vars=[\"label\"], \n",
    "        value_name=\"masked_features\"\n",
    "    )\n",
    "    return df[['label', 'masked_features']]\n",
    "\n",
    "def pad_signal_librosa(data, max_length = 157409):\n",
    "    data = librosa.util.fix_length(data=data, size=MAX_LENGTH)\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "# def pad_signal_pydub(data, max_length = 157409):\n",
    "#     data =librosa.util.fix_length(data=data, size=MAX_LENGTH)\n",
    "#     final_data = nr.reduce_noise(y=data, \n",
    "#                           y_noise=data, \n",
    "#                           sr=22050)\n",
    "#     return np.array(final_data, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3831065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_signal_librosa(\n",
    "    df,\n",
    "    noise=False,\n",
    "    time_shifting=False,\n",
    "    pitch_shifting=False,\n",
    "    time_stretching_faster=False,\n",
    "    time_stretching_slower=False):\n",
    "    \n",
    "\n",
    "    noised_signal = []\n",
    "    pitched_signal = []\n",
    "    time_shifted_signal = []\n",
    "    faster_signal = []\n",
    "    slower_signal = []\n",
    "    features = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        signal = np.array(row['signal'])\n",
    "     \n",
    "        if noise:\n",
    "            noised = add_noise(signal)\n",
    "            noised = pad_signal_librosa(noised)\n",
    "            noised = get_features(noised)\n",
    "            noised_signal.append(noised)\n",
    "\n",
    "            \n",
    "        if pitch_shifting:\n",
    "            pitched = add_pitch_shifting(signal)\n",
    "            pitched = pad_signal_librosa(pitched)\n",
    "            pitched = get_features(pitched)\n",
    "            pitched_signal.append(pitched)\n",
    "            \n",
    "        if time_shifting:\n",
    "            time = pad_signal_librosa(signal)\n",
    "            time = add_time_shifting(time)\n",
    "            time = get_features(time)\n",
    "            time_shifted_signal.append(time)\n",
    "                \n",
    "        if time_stretching_faster:\n",
    "            faster = add_time_stretching_faster(signal)\n",
    "            faster = pad_signal_librosa(faster)\n",
    "            faster = get_features(faster)\n",
    "            faster_signal.append(faster)\n",
    "            \n",
    "        if time_stretching_slower:\n",
    "            slower = add_time_stretching_slower(signal)\n",
    "            slower = pad_signal_librosa(slower)\n",
    "            slower = get_features(slower)\n",
    "            slower_signal.append(slower)\n",
    "            \n",
    "        padded = pad_signal_librosa(signal)\n",
    "\n",
    "        feature = get_features(padded)\n",
    "        features.append(feature)\n",
    "\n",
    "    df['unaug_features'] = features\n",
    "    print('Done with the unaugumented samples')\n",
    "    \n",
    "    if noise:\n",
    "        df['noised_features'] = noised_signal\n",
    "        print('Done adding noise')\n",
    "        \n",
    "    if pitch_shifting:\n",
    "        df['pitched_features'] = pitched_signal\n",
    "        print('Done pitch_shifting')\n",
    "        \n",
    "    if time_shifting:\n",
    "        df['time_shifted_features'] = time_shifted_signal\n",
    "        print('Done time_shifting')\n",
    "        \n",
    "    if time_stretching_faster:\n",
    "        df['faster_features'] = faster_signal\n",
    "        print('Done time_stretching_faster')\n",
    "        \n",
    "    if time_stretching_slower:\n",
    "        df['slower_features'] = slower_signal\n",
    "        print('Done time_stretching_slower')\n",
    "        \n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# def augment_signal_pydub(\n",
    "#     df,\n",
    "#     noise=False,\n",
    "#     time_shifting=False,\n",
    "#     pitch_shifting=False,\n",
    "#     time_stretching_faster=False,\n",
    "#     time_stretching_slower=False):\n",
    "    \n",
    "\n",
    "#     noised_signal = []\n",
    "#     pitched_signal = []\n",
    "#     time_shifted_signal = []\n",
    "#     faster_signal = []\n",
    "#     slower_signal = []\n",
    "#     features = []\n",
    "    \n",
    "#     for index, row in df.iterrows():\n",
    "#         signal = np.array(row['signal'])\n",
    "         \n",
    "#         if noise:\n",
    "#             noised = add_noise(signal)\n",
    "#             noised = pad_signal_pydub(noised)\n",
    "#             noised = get_features(noised)\n",
    "#             noised_signal.append(noised)\n",
    "\n",
    "            \n",
    "#         if pitch_shifting:\n",
    "#             pitched = add_pitch_shifting(signal)\n",
    "#             pitched = pad_signal_pydub(pitched)\n",
    "#             pitched = get_features(pitched)\n",
    "#             pitched_signal.append(pitched)\n",
    "            \n",
    "#         if time_shifting:\n",
    "#             time = pad_signal_pydub(signal)\n",
    "#             time = add_time_shifting(time)\n",
    "#             time = get_features(time)\n",
    "#             time_shifted_signal.append(time)\n",
    "                \n",
    "#         if time_stretching_faster:\n",
    "#             faster = add_time_stretching_faster(signal)\n",
    "#             faster = pad_signal_pydub(faster)\n",
    "#             faster = get_features(faster)\n",
    "#             faster_signal.append(faster)\n",
    "            \n",
    "#         if time_stretching_slower:\n",
    "#             slower = add_time_stretching_slower(signal)\n",
    "#             slower = pad_signal_pydub(slower)\n",
    "#             slower = get_features(slower)\n",
    "#             slower_signal.append(slower)\n",
    "            \n",
    "#         padded = pad_signal_pydub(signal)\n",
    "        \n",
    "        \n",
    "#         feature = get_features(padded)\n",
    "#         features.append(feature)\n",
    "\n",
    "#     df['unaug_features'] = features\n",
    "#     print('Done with the unaugumented samples')\n",
    "    \n",
    "#     if noise:\n",
    "#         df['noised_features'] = noised_signal\n",
    "#         print('Done adding noise')\n",
    "        \n",
    "#     if pitch_shifting:\n",
    "#         df['pitched_features'] = pitched_signal\n",
    "#         print('Done pitch_shifting')\n",
    "        \n",
    "#     if time_shifting:\n",
    "#         df['time_shifted_features'] = time_shifted_signal\n",
    "#         print('Done time_shifting')\n",
    "        \n",
    "#     if time_stretching_faster:\n",
    "#         df['faster_features'] = faster_signal\n",
    "#         print('Done time_stretching_faster')\n",
    "        \n",
    "#     if time_stretching_slower:\n",
    "#         df['slower_features'] = slower_signal\n",
    "#         print('Done time_stretching_slower')\n",
    "        \n",
    "    \n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ef30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_signal_df(df):\n",
    "    \n",
    "    df = df[['emotion', 'label'] + list(df.filter(regex='_features$'))]\n",
    "    df = df.melt(\n",
    "        id_vars=['emotion', \"label\"], \n",
    "        value_name=\"features\"\n",
    "    )\n",
    "    return df[['label', 'features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bd97306",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREMA_df = pd.read_pickle('CREMA_M_df.pkl')\n",
    "RAVDESS_df = pd.read_pickle('RAVDESS_M_df.pkl')\n",
    "SAVEE_df = pd.read_pickle('SAVEE_df.pkl')\n",
    "# TESS_df = pd.read_pickle('TESS_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a28819fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([RAVDESS_df, SAVEE_df, CREMA_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e2ac1ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_df = get_signal(all_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ba1fab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>trimmed_librosa_signals</th>\n",
       "      <th>librosa_lens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>[-0.00012082751, -0.0005314536, -0.00022877126...</td>\n",
       "      <td>29184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>[-0.0005309384, 0.00028353286, 0.00044418397, ...</td>\n",
       "      <td>29696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>[2.0554473e-05, 0.00054405327, 0.00017764534, ...</td>\n",
       "      <td>29184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>[0.0012361169, 0.0013529633, 0.00049721624, 0....</td>\n",
       "      <td>27648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happiness</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>[-4.820062e-05, 3.8167676e-05, -4.1627845e-05,...</td>\n",
       "      <td>34304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion                                               path  \\\n",
       "0    neutral  E:\\Dissertation/RAVDESS/audio_speech_actors_01...   \n",
       "1    neutral  E:\\Dissertation/RAVDESS/audio_speech_actors_01...   \n",
       "2    neutral  E:\\Dissertation/RAVDESS/audio_speech_actors_01...   \n",
       "3    neutral  E:\\Dissertation/RAVDESS/audio_speech_actors_01...   \n",
       "4  happiness  E:\\Dissertation/RAVDESS/audio_speech_actors_01...   \n",
       "\n",
       "                             trimmed_librosa_signals  librosa_lens  \n",
       "0  [-0.00012082751, -0.0005314536, -0.00022877126...         29184  \n",
       "1  [-0.0005309384, 0.00028353286, 0.00044418397, ...         29696  \n",
       "2  [2.0554473e-05, 0.00054405327, 0.00017764534, ...         29184  \n",
       "3  [0.0012361169, 0.0013529633, 0.00049721624, 0....         27648  \n",
       "4  [-4.820062e-05, 3.8167676e-05, -4.1627845e-05,...         34304  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a94e6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa_df = pd.DataFrame()\n",
    "librosa_df['emotion'] = all_df['emotion']\n",
    "librosa_df['signal'] = all_df['trimmed_librosa_signals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a4339c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pydub_df = pd.DataFrame()\n",
    "# pydub_df['emotion'] = all_df['emotion']\n",
    "# pydub_df['signal'] = all_df['trimmed_pydub_signals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f112b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90431015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augument_samples(df, encoder_name):\n",
    "    print(f'{datetime.datetime.now()}: Start augmenting...')\n",
    "    ######## SET 1 ########\n",
    "    set_df = df.copy().reset_index(drop=True)\n",
    "    del df\n",
    "    ######## encoder #########\n",
    "    label_col = 'emotion' if 'emotion' in set_df.columns else 'sex_emotion'\n",
    "    \n",
    "    ohc = OneHotEncoder(sparse=False)\n",
    "    ohc_labels = ohc.fit_transform(set_df[label_col].values.reshape(-1, 1))\n",
    "    joblib.dump(ohc, f'{encoder_name}_ohe.joblib')\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le_labels = le.fit_transform(set_df[label_col])\n",
    "    np.save(f'{encoder_name}_classes', le.classes_)\n",
    "    \n",
    "    set_df['label'] = pd.Series(list(ohc_labels))\n",
    "#     scaler = StandardScaler()\n",
    "    unprocessed_train_df, unprocessed_validation_df, unprocessed_test_df = split_train_validation_test(set_df.copy())\n",
    "    \n",
    "    valid_config = {\n",
    "#         'noise': True,\n",
    "#         'time_shifting': True,\n",
    "#         'pitch_shifting': True,\n",
    "#         'time_stretching_faster': True,\n",
    "#         'time_stretching_slower': True\n",
    "    }\n",
    "    \n",
    "    train_config = {\n",
    "#         'noise': True,\n",
    "#         'time_shifting': True,\n",
    "#         'pitch_shifting': True,\n",
    "#         'time_stretching_faster': True,\n",
    "#         'time_stretching_slower': True\n",
    "    }\n",
    "    \n",
    "    #train\n",
    "#     if data == 'librosa':\n",
    "    augmented_df = augment_signal_librosa(unprocessed_train_df.copy(), **train_config)\n",
    "#     else:\n",
    "#         augmented_df = augment_signal_pydub(unprocessed_train_df.copy(), **train_config)\n",
    "    del unprocessed_train_df\n",
    "    train_df = melt_signal_df(augmented_df.copy())\n",
    "#     train_df['features'] = train_df['features'].apply(lambda x: scaler.fit_transform(x))\n",
    "    #for mfcc aug\n",
    "#     train_df = augument_mfcc(train_df.copy())\n",
    "#     train_df = melt_mfcc_df(train_df.copy())\n",
    "    \n",
    "    del augmented_df\n",
    "    print(f'{datetime.datetime.now()}: Done train set')\n",
    "    \n",
    "    # validation\n",
    "#     if data == 'librosa':\n",
    "    processed_df = augment_signal_librosa(unprocessed_validation_df.copy(), **valid_config)\n",
    "#     else:\n",
    "#         processed_df = augment_signal_pydub(unprocessed_validation_df.copy(), **valid_config)\n",
    "    del unprocessed_validation_df\n",
    "    validation_df = melt_signal_df(processed_df.copy())\n",
    "#     scaler = StandardScaler()\n",
    "#     validation_df['features'] = validation_df['features'].apply(lambda x: scaler.fit_transform(x))\n",
    "    del processed_df\n",
    "    print(f'{datetime.datetime.now()}: Done validation set')\n",
    "    \n",
    "    # test\n",
    "#     if data == 'librosa':\n",
    "    processed_df = augment_signal_librosa(unprocessed_test_df.copy(), **valid_config)\n",
    "#     else:\n",
    "#         processed_df = augment_signal_pydub(unprocessed_test_df.copy(), **valid_config)\n",
    "    del unprocessed_test_df\n",
    "    test_df = melt_signal_df(processed_df.copy())\n",
    "#     scaler = StandardScaler()\n",
    "#     test_df['features'] = test_df['features'].apply(lambda x: scaler.fit_transform(x))\n",
    "    del processed_df\n",
    "    \n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fa3a5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-15 00:13:04.944482: Start augmenting...\n",
      "Done with the unaugumented samples\n",
      "2022-06-15 00:14:01.313478: Done train set\n",
      "Done with the unaugumented samples\n",
      "2022-06-15 00:14:09.216752: Done validation set\n",
      "Done with the unaugumented samples\n"
     ]
    }
   ],
   "source": [
    "all_samples_train, all_samples_valid, all_samples_test = augument_samples(librosa_df, encoder_name = 'librosa_all_samples')\n",
    "all_samples_train.to_pickle('librosa_all_samples_train.pkl')\n",
    "all_samples_valid.to_pickle('librosa_all_samples_valid.pkl')\n",
    "all_samples_test.to_pickle('librosa_all_samples_test.pkl')\n",
    "del librosa_df\n",
    "del all_samples_train\n",
    "del all_samples_valid\n",
    "del all_samples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "111d5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_samples_train, all_samples_valid, all_samples_test = augument_samples(pydub_df, encoder_name = 'pydub_all_samples', data = 'pydub')\n",
    "# all_samples_train.to_pickle('pydub_all_samples_train.pkl')\n",
    "# all_samples_valid.to_pickle('pydub_all_samples_valid.pkl')\n",
    "# all_samples_test.to_pickle('pydub_all_samples_test.pkl')\n",
    "# del pydub_df\n",
    "# del all_samples_train\n",
    "# del all_samples_valid\n",
    "# del all_samples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a5fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex1 = pydub_df[:10]\n",
    "# ex2 = librosa_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "629e06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex1_train, ex1_valid, ex1_test = augument_samples(ex1, encoder_name = 'test', data = 'pydub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68314906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ex1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3bdd654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.stack([np.array(val) for val in ex1_train['masked_features'].values], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d5d500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8fa3600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ex1_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d1e359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c5e7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex2_train, ex2_valid, ex2_test = augument_samples(ex2, encoder_name = 'test2', data = 'librosa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bef14883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a93a7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex2_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ea03f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex2_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab33e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import keras\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
    "from keras.layers import Bidirectional, LSTM, Reshape\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c86462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "cwd = os.getcwd()\n",
    "CREMA = cwd + \"/CREMA/\"\n",
    "RAVDESS = cwd + \"/RAVDESS/audio_speech_actors_01-24/\"\n",
    "SAVEE = cwd + \"/SAVEE/\"\n",
    "TESS = cwd + \"/TESS/TESS_Toronto_emotional_speech_set_data/\"\n",
    "set1 = ['emotion', 'path', 'Sex']\n",
    "set2 = ['sex_emotion', 'path','Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c2d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_signal_file_to_df(df: pd.DataFrame, path: str) -> pd.DataFrame:\n",
    "    \"\"\".\"\"\"\n",
    "    df[['signal', 'signal_sr']] = pd.DataFrame(\n",
    "        data=df['filename'].apply(lambda x: librosa.load(os.path.join(path, x))).to_list(),\n",
    "        columns=['signal', 'signal_sr']\n",
    "    )\n",
    "    \n",
    "    df['signal'] = df['signal'].apply(lambda x: librosa.util.normalize(x))\n",
    "    df['len_signal'] = df['signal'].apply(lambda x: len(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c515dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_to_df_crema(file_list: list):\n",
    "    \"\"\".\"\"\"\n",
    "    \n",
    "    columns = ['ActorID', 'sentence', 'emotion_id', 'emotion', 'quantifier', 'path']\n",
    "    emotion_dict = {\n",
    "        \"SAD\": \"sadness\", \n",
    "        \"ANG\": \"anger\", \n",
    "        \"DIS\": \"disgust\", \n",
    "        \"FEA\": \"fear\", \n",
    "        \"HAP\": \"happiness\", \n",
    "        \"NEU\": \"neutral\"\n",
    "    }\n",
    "    file_df = pd.DataFrame(columns=columns)\n",
    "    for file in file_list:\n",
    "        file_as_list = file.split('_')\n",
    "        row = pd.DataFrame(\n",
    "            data={\n",
    "                'ActorID': file_as_list[0],\n",
    "                'sentence': file_as_list[1],\n",
    "                'emotion_id': file_as_list[2],\n",
    "                'emotion': emotion_dict[file_as_list[2]],\n",
    "                'quantifier': file_as_list[3].split('.')[0],\n",
    "                'path': os.path.join(CREMA,\"AudioWAV/\", file)\n",
    "            },\n",
    "            columns=columns,\n",
    "            index=[0]\n",
    "        )\n",
    "        file_df = file_df.append(row, ignore_index=True)\n",
    "    return file_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_data_crema(path):\n",
    "    data = os.path.join(path, \"AudioWAV/\")\n",
    "    file_list = os.listdir(data)\n",
    "    speaker_df = pd.read_csv(f'{path}VideoDemographics.csv', dtype=str).apply(lambda x: x.astype(str).str.lower())\n",
    "    file_df = file_list_to_df_crema(file_list)\n",
    "    data_df = speaker_df.merge(file_df, on='ActorID')\n",
    "    data_df['sex_emotion'] = data_df['Sex'] + '_' + data_df['emotion']\n",
    "#     data_df = read_signal_file_to_df(data_df.copy(deep=True), path=data)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265615f2",
   "metadata": {},
   "source": [
    "# CREMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5f805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = get_data_crema(CREMA)\n",
    "original_CREMA_df = data_df[set1].copy().reset_index(drop=True)\n",
    "# CREMA_df2 = data_df[set2].copy().reset_index(drop=True)\n",
    "# CREMA_M_df = data_df[data_df['Sex']=='male'].copy()[set1].reset_index(drop=True)\n",
    "# CREMA_F_df = data_df[data_df['Sex']=='female'].copy()[set1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c08352fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf118ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/CREMA/AudioWAV/1001_DFA_ANG_XX...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>E:\\Dissertation/CREMA/AudioWAV/1001_DFA_DIS_XX...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fear</td>\n",
       "      <td>E:\\Dissertation/CREMA/AudioWAV/1001_DFA_FEA_XX...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happiness</td>\n",
       "      <td>E:\\Dissertation/CREMA/AudioWAV/1001_DFA_HAP_XX...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>E:\\Dissertation/CREMA/AudioWAV/1001_DFA_NEU_XX...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     emotion                                               path   Sex\n",
       "0      anger  E:\\Dissertation/CREMA/AudioWAV/1001_DFA_ANG_XX...  male\n",
       "1    disgust  E:\\Dissertation/CREMA/AudioWAV/1001_DFA_DIS_XX...  male\n",
       "2       fear  E:\\Dissertation/CREMA/AudioWAV/1001_DFA_FEA_XX...  male\n",
       "3  happiness  E:\\Dissertation/CREMA/AudioWAV/1001_DFA_HAP_XX...  male\n",
       "4    neutral  E:\\Dissertation/CREMA/AudioWAV/1001_DFA_NEU_XX...  male"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_CREMA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb7841b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREMA_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbdde16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREMA_M_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22798b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CREMA_F_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46cb3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_CREMA_df.to_pickle('original_CREMA_df.pkl')\n",
    "# CREMA_df2.to_pickle('CREMA_df2.pkl')\n",
    "# CREMA_M_df.to_pickle('CREMA_M_df.pkl')\n",
    "# CREMA_F_df.to_pickle('CREMA_F_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "722c6ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del original_CREMA_df\n",
    "# del CREMA_df2\n",
    "# del CREMA_M_df\n",
    "# del CREMA_F_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d02caa",
   "metadata": {},
   "source": [
    "# RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd8eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_to_df_ravdess(file_list: list):\n",
    "    \"\"\".\"\"\"\n",
    "    \n",
    "    columns = ['modality', 'vocal_channel', 'emotion', 'emotion_intensity', 'statement', 'repetition', 'Sex', 'path']\n",
    "    emotion_dict = {\n",
    "        \"01\": \"neutral\", \n",
    "        \"02\": \"calmness\", \n",
    "        \"03\": \"happiness\", \n",
    "        \"04\": \"sadness\", \n",
    "        \"05\": \"anger\", \n",
    "        \"06\": \"fear\",\n",
    "        \"07\": \"disgust\",\n",
    "        \"08\": \"surprise\",\n",
    "    }\n",
    "    file_df = pd.DataFrame(columns=columns)\n",
    "    for file in file_list:\n",
    "        file_as_list = file.split('/')[1].split('-')\n",
    "        row = pd.DataFrame(\n",
    "            data={\n",
    "                'modality': file_as_list[0],\n",
    "                'vocal_channel': file_as_list[1],\n",
    "                'emotion': emotion_dict[file_as_list[2]],\n",
    "                'emotion_intensity': file_as_list[3],\n",
    "                'statement': file_as_list[4],\n",
    "                'repetition': file_as_list[5],\n",
    "                'Sex': 'female' if int(file_as_list[6].split('.')[0])%2 == 0 else 'male',\n",
    "                'path': os.path.join(RAVDESS, file)\n",
    "            },\n",
    "            columns=columns,\n",
    "            index=[0]\n",
    "        )\n",
    "        file_df = file_df.append(row, ignore_index=True)\n",
    "#     file_df = file_df[file_df['emotion']!='calmness'].reset_index(drop=True)\n",
    "    return file_df\n",
    "\n",
    "def get_data_ravdess():\n",
    "    folder_list = os.listdir(RAVDESS)\n",
    "    file_list = []\n",
    "    for folder in folder_list:\n",
    "        for file in os.listdir(RAVDESS+folder):\n",
    "            file_list.append(f'{folder}/{file}')\n",
    "            \n",
    "    data_df = file_list_to_df_ravdess(file_list)\n",
    "    data_df['sex_emotion'] = data_df['Sex'] + '_' + data_df['emotion']\n",
    "#     data_df = read_signal_file_to_df(data_df.copy(deep=True), path=RAVDESS)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ff5a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = get_data_ravdess()\n",
    "original_RAVDESS_df = data_df[set1].copy().reset_index(drop=True)\n",
    "# RAVDESS_df2 = data_df[set2].copy().reset_index(drop=True)\n",
    "# RAVDESS_M_df = data_df[data_df['Sex']=='male'].copy()[set1].reset_index(drop=True)\n",
    "# RAVDESS_F_df = data_df[data_df['Sex']=='female'].copy()[set1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d13d0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d89ee7ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RAVDESS_df.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fbef0bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RAVDESS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7e8a1d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calmness</td>\n",
       "      <td>E:\\Dissertation/RAVDESS/audio_speech_actors_01...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion                                               path   Sex\n",
       "0   neutral  E:\\Dissertation/RAVDESS/audio_speech_actors_01...  male\n",
       "1   neutral  E:\\Dissertation/RAVDESS/audio_speech_actors_01...  male\n",
       "2   neutral  E:\\Dissertation/RAVDESS/audio_speech_actors_01...  male\n",
       "3   neutral  E:\\Dissertation/RAVDESS/audio_speech_actors_01...  male\n",
       "4  calmness  E:\\Dissertation/RAVDESS/audio_speech_actors_01...  male"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_RAVDESS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a49fcb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAVDESS_M_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14475384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RAVDESS_F_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9326b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_RAVDESS_df.to_pickle('original_RAVDESS_df.pkl')\n",
    "# RAVDESS_df2.to_pickle('RAVDESS_df2.pkl')\n",
    "# RAVDESS_M_df.to_pickle('RAVDESS_M_df.pkl')\n",
    "# RAVDESS_F_df.to_pickle('RAVDESS_F_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a058d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del RAVDESS_df\n",
    "# del RAVDESS_df2\n",
    "# del RAVDESS_M_df\n",
    "# del RAVDESS_F_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab03581",
   "metadata": {},
   "source": [
    "# SAVEE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27b764a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_to_df_savee(file_list: list):\n",
    "    \"\"\".\"\"\"\n",
    "    \n",
    "    emotion=[]\n",
    "    path = []\n",
    "    for i in file_list:\n",
    "        if i[-8:-6]=='_a':\n",
    "            emotion.append('anger')\n",
    "        elif i[-8:-6]=='_d':\n",
    "            emotion.append('disgust')\n",
    "        elif i[-8:-6]=='_f':\n",
    "            emotion.append('fear')\n",
    "        elif i[-8:-6]=='_h':\n",
    "            emotion.append('happiness')\n",
    "        elif i[-8:-6]=='_n':\n",
    "            emotion.append('neutral')\n",
    "        elif i[-8:-6]=='sa':\n",
    "            emotion.append('sadness')\n",
    "        elif i[-8:-6]=='su':\n",
    "            emotion.append('surprise')\n",
    "        else:\n",
    "            emotion.append('unknown') \n",
    "        path.append(os.path.join(SAVEE, i))\n",
    "\n",
    "    # Now check out the label count distribution \n",
    "    file_df = pd.DataFrame(emotion, columns=['emotion'])\n",
    "    file_df['Sex'] = 'male'\n",
    "    file_df = pd.concat([file_df, pd.DataFrame(path, columns=['path'])], axis=1)\n",
    "#     file_df = file_df[file_df['emotion']!='unknown'].reset_index(drop=True)\n",
    "    return file_df\n",
    "\n",
    "def get_data_savee():\n",
    "    file_list = os.listdir(SAVEE)\n",
    "    data_df = file_list_to_df_savee(file_list)\n",
    "    data_df['sex_emotion'] = data_df['Sex'] + '_' + data_df['emotion']\n",
    "#     data_df = read_signal_file_to_df(data_df.copy(deep=True), path=SAVEE)\n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "808ff791",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = get_data_savee()\n",
    "original_SAVEE_df = data_df[set1].copy().reset_index(drop=True)\n",
    "# SAVEE_df2 = data_df[set2].copy().reset_index(drop=True)\n",
    "# SAVEE_M_df = data_df[data_df['Sex']=='male'].copy()[set1].reset_index(drop=True)\n",
    "# SAVEE_F_df = data_df[data_df['Sex']=='female'].copy()[set1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15cd3472",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ec00fd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/SAVEE/DC_a01.wav</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/SAVEE/DC_a02.wav</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/SAVEE/DC_a03.wav</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/SAVEE/DC_a04.wav</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/SAVEE/DC_a05.wav</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion                              path   Sex\n",
       "0   anger  E:\\Dissertation/SAVEE/DC_a01.wav  male\n",
       "1   anger  E:\\Dissertation/SAVEE/DC_a02.wav  male\n",
       "2   anger  E:\\Dissertation/SAVEE/DC_a03.wav  male\n",
       "3   anger  E:\\Dissertation/SAVEE/DC_a04.wav  male\n",
       "4   anger  E:\\Dissertation/SAVEE/DC_a05.wav  male"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_SAVEE_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "477a41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVEE_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6183f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_SAVEE_df.to_pickle('original_SAVEE_df.pkl')\n",
    "# SAVEE_df2.to_pickle('SAVEE_df2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f62de642",
   "metadata": {},
   "outputs": [],
   "source": [
    "del original_SAVEE_df\n",
    "# del SAVEE_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d5de3b",
   "metadata": {},
   "source": [
    "# TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a83bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_to_df_tess(file_list: list):\n",
    "    \"\"\".\"\"\"\n",
    "    # Get the data location for TESS\n",
    "    path = []\n",
    "    emotion = []\n",
    "    dir_list = os.listdir(TESS)\n",
    "\n",
    "    for i in dir_list:\n",
    "        fname = os.listdir(TESS + i)   \n",
    "        for f in fname:\n",
    "            if i == 'OAF_angry' or i == 'YAF_angry':\n",
    "                emotion.append('anger')\n",
    "            elif i == 'OAF_disgust' or i == 'YAF_disgust':\n",
    "                emotion.append('disgust')\n",
    "            elif i == 'OAF_Fear' or i == 'YAF_fear':\n",
    "                emotion.append('fear')\n",
    "            elif i == 'OAF_happy' or i == 'YAF_happy':\n",
    "                emotion.append('happiness')\n",
    "            elif i == 'OAF_neutral' or i == 'YAF_neutral':\n",
    "                emotion.append('neutral')                                \n",
    "            elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n",
    "                emotion.append('surprise')               \n",
    "            elif i == 'OAF_Sad' or i == 'YAF_sad':\n",
    "                emotion.append('sadness')\n",
    "            else:\n",
    "                emotion.append('unknown')\n",
    "            path.append(os.path.join(TESS, f'{i}/{f}'))\n",
    "\n",
    "    file_df = pd.DataFrame(emotion, columns = ['emotion'])\n",
    "    file_df['Sex'] = 'female'\n",
    "    file_df = pd.concat([file_df, pd.DataFrame(path, columns=['path'])], axis=1)\n",
    "#     file_df = file_df[file_df['emotion']!='unknown'].reset_index(drop=True)\n",
    "    return file_df\n",
    "\n",
    "def get_data_tess():\n",
    "    file_list = os.listdir(TESS)\n",
    "    data_df = file_list_to_df_tess(file_list)\n",
    "    data_df['sex_emotion'] = data_df['Sex'] + '_' + data_df['emotion']\n",
    "#     data_df = read_signal_file_to_df(data_df.copy(deep=True), path=TESS)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49ccc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = get_data_tess()\n",
    "original_TESS_df = data_df[set1].copy().reset_index(drop=True)\n",
    "# TESS_df2 = data_df[set2].copy().reset_index(drop=True)\n",
    "# TESS_M_df = data_df[data_df['Sex']=='male'].copy()[set1].reset_index(drop=True)\n",
    "# TESS_F_df = data_df[data_df['Sex']=='female'].copy()[set1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6e16fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a3a8f16",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emotion                                               path     Sex\n",
       "0   anger  E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...  female\n",
       "1   anger  E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...  female\n",
       "2   anger  E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...  female\n",
       "3   anger  E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...  female\n",
       "4   anger  E:\\Dissertation/TESS/TESS_Toronto_emotional_sp...  female"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_TESS_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0228e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESS_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "571f50ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_TESS_df.to_pickle('original_TESS_df.pkl')\n",
    "# TESS_df2.to_pickle('TESS_df2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e9e4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del TESS_df\n",
    "# del TESS_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7281db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_from_df(df, row_nr = None):\n",
    "    if not row_nr:\n",
    "        n_rows = df.shape[0]\n",
    "        row_nr = np.random.randint(0, n_rows)\n",
    "    return df.iloc[row_nr]\n",
    "\n",
    "\n",
    "def do(sample):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    librosa.display.waveshow(sample['signal'], sr = 22050)\n",
    "    plt.title('signal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48f33979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do(get_sample_from_df(CREMA_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5e39ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do(get_sample_from_df(RAVDESS_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f9f4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do(get_sample_from_df(SAVEE_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d0ef76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do(get_sample_from_df(TESS_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb05a9",
   "metadata": {},
   "source": [
    "# Concatenate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72e3f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = pd.concat([TESS_df, SAVEE_df, CREMA_df, RAVDESS_df]).reset_index(drop=True)\n",
    "# all_df2 = pd.concat([TESS_df2, SAVEE_df2, CREMA_df2, RAVDESS_df2]).reset_index(drop=True)\n",
    "# all_M_df = pd.concat([SAVEE_df, CREMA_M_df, RAVDESS_M_df]).reset_index(drop=True)\n",
    "# all_F_df = pd.concat([TESS_df, CREMA_F_df, RAVDESS_F_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a1100",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22da8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df.to_pickle('all_samples.pkl')\n",
    "# all_df2.to_pickle('all_samples2.pkl')\n",
    "# all_M_df.to_pickle('male_samples.pkl')\n",
    "# all_F_df.to_pickle('female_samples.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c94c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "# df = pd.read_pickle('male_samples.pkl')\n",
    "# df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
